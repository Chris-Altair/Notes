ps：没想到我工作中干了不少数据抽取的事（可惜代码我没存下来），所以稍微整理下，注意以下所说的”数据抽取“指的都是通过代码实现而不是指的通过Kettle等工具实现，适用于小而灵活的、需要自己实现的场景，大场面老实用业界成熟方案吧。此外下面也纯属个人理解的，不一定正确，仅供参考。

## 1. 一些概念准备

- 数据抽取：简单理解，将数据从数据源source提取，并通过某种规则rule转换成另一种格式，然后存到目标系统target中

- source：包括但不限于数据库，可能是excel、txt甚至可能是自己定义的二进制文件等。

- target：跟source一样，一般是数据库，但也不排除其他。

- extraction rule：抽取规则，决定抽取哪些数据。

- conversion rule：转换规则，将source数据的格式转成target的格式

- storage rule：数据存储策略，决定如何将数据存储。

- exception handle：对于处理过程出现失败的数据的处理方式。

  基本上面这些概念已经能满足一个完备的数据抽取实现了。

  一个最简单也最典型的数据抽取：从数据库A中a表的数据转换一下存到B库的b表中。

## 2. 基本思路

**关键词：id生成、连接池、分批次、多线程、异常处理**

一个基本的思路是尽量

### ① id生成

对应数据存在关联关系的情况，数据id是数据库自增还是自己定义对于处理方式的影响很大，一般都是自定义id（自增id处理关联关系很麻烦），可以使用雪花算法或者其他线程安全的方式生成id

### ② 连接池设置

对于source/target为数据库的情况下，每次都建立数据库链接肯定会影响处理效率，所以必然要建立**数据库连接池**，后续读取/存储数据链接都是从连接池获取，然后后续一般连接数的设置跟处理器核数成**正比**关系。

若存在多数据源的情况，可以考虑把数据库连接池存在map里，通过唯一key获取，然后将线程池放到线程缓存里供后续使用。

### ③ 分批次处理

数据必然要按**批次**处理，毕竟每次处理1条或者一次全处理在数据量较大的情况下，正常人不会这么干。所以统一的处理单位是批次，抽取按批次、转换按批次、存储也按批次。

要考虑**服务器的堆内存**（java），若数据量太大可能导致oom，所以对于处理完的批次要**收回强引用**，避免无法垃圾回收掉。

批次内要放多少数据要考虑**数据库**和**数据本身的大小**，一次提交太多的话，大事务会影响处理效率，而且一般数据库也会限制sql发包的大小（超过会报错）。

ps：mysql可考虑：https://www.imooc.com/article/291781

ps：批次的处理实现是使用**垂直**（每个批次链式调用）还是**水平**（传统的过程式处理）是一个值得思考的问题。

### ④ 多线程处理

充分利用资源可以考虑**多线程**，不同**线程池**处理不同种类的任务（例如转换线程池、存储线程池）。主要是利用数据抽取是io密集型任务，利用io空闲时间可以做转换等其他不需要io的操作。

一般的数据抽取/迁移至少会有一个线程池负责数据存储。

线程数的设置一般跟处理器核数成**正比**关系。

```java
//看到有专门干数据抽取的开发是这么写的，先把数据都查出来，然后用CountDownLatch控制任务都执行完，也算是一种思路吧
CountDownLatch latch = new CountDownLatch(batchSize);
threadPoolExecutor.execute(()->{
    try {
        //batchInsert
    } catch(Exception e) {
        
    } finally {
        latch.countDown();
    }
});
latch.await();
```

### ⑤ 异常处理

**异常处理**也很关键，如果某个批次处理出现错误了，不应该影响其他批次，这也是使用多线程的原因；此外若某个批次出现错误，则需要记录这批出错的数据，以便人工排查，例如可以考虑记录到错误表中，或者写到某个文件中。

### ⑥ 其他

此外还可以根据数据转换比例（例如源：目标=5：1之类的）考虑合并批次等”高级“操作，但这并非必须，还是得结合实际情况看是否使用。

程序步骤大体如下（根据实现方式，代码结构可能有很大不同，但逻辑是相似的，最简单的情况是只有存储线程池）：

```
按批次抽取数据，将批次提交到【转换任务队列】
转换线程池监听【转换任务队列】处理批次，处理成功将批次提交到【存储任务队列】
存储线程池监听【存储任务队列】处理批次，成功执行完说明这一批次执行成功
中途任一步骤处理失败则将批次提交到【异常处理队列】，由异常处理线程池处理
```

## 3. 抽取规则

抽取规则主要考虑两个方面的问题：

1. 业务上：按哪些条件抽数据，例如按时间范围、按状态等等
2. 性能上：根据source的不同，实现抽取的方式也不同

下面列一些常用的source种类：

1. 数据库：最常见的方式，大量抽取的时候要考虑**根据索引按批次抽取**，如果是多数据源的话，可以考虑维护个数据库连接池map，每个线程处理前维护个threadLocal存要用的连接池，处理完再清除掉。
2. excel：按行范围生成批次。
3. 文本文件：json、xml、txt之类。
4. 二进制文件：根据文件结构读文件转成对象。

## 4. 转换规则

可以考虑使用注解、反射等方式将源数据类转成目标类

## 5. 存储规则

一般使用多线程存，当然如果target是单一文件之类的情况肯定不考虑这种情况了。
